<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>Interplay of Light :: filipecn</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="This text is just my personal notes on BRDFs. The text is heavily based on these references: real time rendering book, learn opengl website, Google&amp;rsquo;s Filament and here.
 Let&amp;rsquo;s consider light modeled as an electromagnetic wave (but treated as a ray when convenient), and our rendered image as the combination of all light that get into the camera sensors.
 An important property of light is the wavelength \(\lambda\), because it is related to the color of a particular light wave." />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<link rel="canonical" href="/post/pbr-area-lights/" />




<link rel="stylesheet" href="/assets/style.css">






<link rel="apple-touch-icon" href="/img/apple-touch-icon-192x192.png">

  <link rel="shortcut icon" href="/favicon.ico">



<meta name="twitter:card" content="summary" />

  
    <meta name="twitter:site" content="" />
  
    <meta name="twitter:creator" content="" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Interplay of Light">
<meta property="og:description" content="A little (and lazy) introduction to Physically Based Shading." />
<meta property="og:url" content="/post/pbr-area-lights/" />
<meta property="og:site_name" content="filipecn" />

  
    <meta property="og:image" content="/favicon.ico">
  

<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">


  <meta property="article:published_time" content="2021-04-13 00:00:00 &#43;0000 UTC" />












<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>





<link rel="stylesheet" href="/publication_container.5744e18b41c64a2d3769f36cb2ca6ffbc84b1fbdc7c7b547c7230eb15dd61432.css">

<link rel="stylesheet" href="/css/projectcard.css">
<link rel="stylesheet" href="/css/smallprojectcard.css">
<link rel="stylesheet" href="/css/faicon.css">


<script src="/js/posts/polygon.js"></script> 
<script src="/js/posts/two.min.js"></script> 
<script src="https://code.jquery.com/jquery-1.9.1.js"></script>



</head>
<body class="orange">


<div class="container center headings--one-size">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    filipecn
  </div>
</a>

    </div>
    
      <div class="menu-trigger">menu</div>
    
  </div>

  <center>
<p></p>
  <strong> CS PhD canditate </strong> | filipedecn@gmail.com | <a href="https://github.com/filipecn">github</a> | <a href="https://www.linkedin.com/in/filipecn/">linkedin</a>
  </center>
  
    <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="/cv">CV</a></li>
        
      
        
          <li><a href="/projects">Projects</a></li>
        
      
        
          <li><a href="/publications">Publications</a></li>
        
      
        
          <li><a href="/post">Posts</a></li>
        
      
        
          <li><a href="/drawing">Drawing</a></li>
        
      
      
    

    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="/cv">CV</a></li>
      
    
      
        <li><a href="/projects">Projects</a></li>
      
    
      
        <li><a href="/publications">Publications</a></li>
      
    
      
        <li><a href="/post">Posts</a></li>
      
    
      
        <li><a href="/drawing">Drawing</a></li>
      
    
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
<div class="post">
  <h1 class="post-title">
    <a href="/post/pbr-area-lights/">Interplay of Light</a></h1>
  <div class="post-meta">
    
      <span class="post-date">
        2021-04-13 
      </span>
    
    
  </div>

  
  <span class="post-tags">
    
    #<a href="/tags/rendering/">rendering</a>&nbsp;
    
    #<a href="/tags/real-time/">real-time</a>&nbsp;
    
  </span>
  

  

  
    <div class="table-of-contents">
      <h2>
        
          Table of Contents
        
      </h2>
      <nav id="TableOfContents">
  <ul>
    <li><a href="#radiance-of-light">Radiance of Light</a></li>
    <li><a href="#brdf">BRDF</a></li>
    <li><a href="#surfaces">Surfaces</a></li>
    <li><a href="#the-microgeometry-of-surfaces">The microgeometry of surfaces</a></li>
    <li><a href="#the-diffuse-contribution">The Diffuse Contribution</a></li>
  </ul>
</nav>
    </div>
  

  <div class="post-content"><div>
        <blockquote>
<p>This text is just my personal notes on BRDFs. The text is heavily based on these references: <a href="https://www.realtimerendering.com/">real time rendering book</a>, <a href="https://learnopengl.com/PBR/Theory">learn opengl website</a>, <a href="https://google.github.io/filament/Filament.md.html#materialsystem/diffusebrdf">Google&rsquo;s Filament</a> and <a href="http://graphicrants.blogspot.com/2013/08/specular-brdf-reference.html">here</a>.</p>
</blockquote>
<p>Let&rsquo;s consider light modeled as an electromagnetic wave (but treated as a ray when convenient), and
our rendered image as the combination of all light that get into the camera sensors.</p>

  <img src="/img/posts/pbr/light.svg"  class="center"  />


<blockquote>
<p>An important property of light is the <em>wavelength</em> \(\lambda\), because it is
related to the color of a particular light wave. Humans, for example, can only perceive light with wavelenghts
ranging from 400 to 700 nanometers.</p>
</blockquote>
<p>As light propagate through media, the interaction with matter (molecules)
deviates the direction of propagation and light gets <strong><em>scattered</em></strong>. Different media will scatter
different light waves in different ways depending on their wavelenghts.</p>
<hr>
<h2 id="radiance-of-light">Radiance of Light<a href="#radiance-of-light" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<p>In Physically Based Rendering (PBR), the <em>radiant energy</em> carried by light waves plays a
central role. From radiant energy we obtain:</p>
<ul>
<li><strong>Radiant Flux</strong> \(\Phi\) measures the flow of radiant energy carried by light. \(\Phi\) is measured in <em>watts</em> (\(W\)).</li>
<li><strong>Irradiance</strong> \(E\) is the density of the radiant flux \(\Phi\) with respect to an area \(A\), i.e., \(d\Phi/dA\). \(E\) is measured in \(W/m^ 2\).</li>
<li><strong>Radiant Intensity</strong> \(I\) is the flux density \(\Phi\) with respect to a <em>solid angle</em> \(\omega\) <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. \(I\) is measured in watts per steradian <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> \(W/sr\).</li>
<li><strong>Radiance</strong> \(L\) is the electromagnetic radiation in a single ray of light. It is
the density of radiant flux with respect to both area and solid angle (\(d^2\Phi/dAd\omega\)). \(L\) is measured in \(W/(m^2sr)\).</li>
</ul>
<p>The radiance entering the camera is what will produce the final image. Measuring the
incoming radiance in a pixel (film sensor) gives the brightness and color for each
ray of light.</p>
<p>Since light spreads in all directions, the radiance \(L\) is actually a distribution function.
A particular radiance measurement, \(L(x,d\)), will depend on a position \(x\) and a direction \(d\). So what we need is to compute the radiance that leaves the surface point in the
direction of the camera <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>.</p>

  <img src="/img/posts/pbr/brdf.svg"  class="center"  />


<p>Given a point \(p\) in the surface to where the camera, at position \(c\), is looking at.
The vectors \(l\) and \(v\) represent the light direction and view direction, respectively
&ndash; both pointing away from the surface (figure). We want to compute the radiance that arrives
from \(l\) and leaves \(p\) in the \(v\) direction.</p>
<blockquote>
<p>If we use the suffix \((\cdot)_i\) for incoming directions and \((\cdot)_o\) for outgoing directions,
then our goal is to compute \(L_o(p,v)\).</p>
</blockquote>
<h2 id="brdf">BRDF<a href="#brdf" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<p>Local reflectance &ndash; the amount of light being reflected in a small region of the surface &ndash; can be
calculated by a <strong><em>Bidirectional Reflectance Distribution Function</em></strong> (BRDF)
$$f(l,v) = f_{spec}(l,v) + f_{diff}(l,v),$$
made of a diffuse component \(f_{diff}\) and a specular component \(f_{spec}\). The specular reflection
component represents light that is reflected directly by the surface of an object. The diffuse component
represents the rest of light that is scattered inside the surface/object before leaving the surface.
For now lets focus on the specular component.</p>
<p>This function depends only on the incoming direction of light \(l\) and an outgoing direction
\(v\) for the reflected light. In other words, for a incoming light direction, this function computes
how much of this light gets reflected into a given outgoing direction. Different BRDFs will
produce different patterns of reflection (see right column in the figure).</p>
<p>To compute the outgoing radiance \(L_o(p, v)\), we need to consider all
incident radiances from all incoming directions. These directions are defined by the
unit hemisphere \(\Omega\) centered in the surface point, and aligned to the surface normal (figure).
Each incoming radiance is then combined with the BRDF to form the <strong><em>reflectance equation</em></strong>:</p>
<p>$$L_o(p,v) = \int_{l\in \Omega}f(l,v)L_i(p,l) n\cdot l dl$$</p>
<blockquote>
<p>The term \(n\cdot l\) scales the radiance based on the incident angle \(\theta_i\) &ndash;
remember that \(n\cdot l = \cos \theta_i\). This term comes from the fact that radiance is
defined over an area \(A\) perpendicular to the light&rsquo;s ray, which is not the case here, as the
tangent plane is perpendicular to the surface normal, and not the light ray (See <a href="https://en.wikipedia.org/wiki/Lambert%27s_cosine_law">Lambert&rsquo;s cosine law</a>).</p>
</blockquote>
<p>In practice, we want to compute the radiance of the 3 wavelengths respective to red, green and
blue, because pixel colors are stored in RGB. The discrete version of the reflectance equation used in shading is</p>
<p>$$L_o(p,v) = \pi \sum^n_{i=1}f(l_i,v)c_{light_i}(n \cdot l_{i})^+,$$</p>
<p>where \(n\) is the number of light sources, \(c_{light_i}\) is the color (radiance) of light \(i\),
and \(l_i\) its direction. Note that we need
to clamp the cosine value since invalid angles (\(l \notin\Omega \)) can appear due to light rays
coming from behind the surface.</p>
<hr>
<p>Essentially the objects in a scene will have different material properties that will
interact with light in different ways. This interaction is defined by the BRDF particular
to each type of material. In the real-time rendering pipeline, we will process a fragment
that represents a piece of surface with a particular BRDF.</p>
<h2 id="surfaces">Surfaces<a href="#surfaces" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<p>An object surface can be seen as an interface between two different media &ndash;
for example, air and metal or water. When light hits such interface, some waves
move forward (called <strong><em>transmitted waves</em></strong>) and some get reflected (called <strong><em>reflected waves</em></strong>).
The transmitted waves suffer alteration in their speed, thus direction gets <strong><em>refracted</em></strong>.</p>

  <img src="/img/posts/pbr/snell.svg"  class="center"  />


<p>The new direction of the refracted light can be calculated from the <em>Snell&rsquo;s law</em>:</p>
<p>$$\sin \theta_t = \frac{\eta_1}{\eta_2}\sin \theta_i$$</p>
<p>where \(\eta_1\) and \(\eta_2\) are the <em>indices of refraction</em> <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> of the
initial medium (top region in the figure above) and destination medium, respectively.
All angles are formed with the normal of the surface at the point of intersection.
The incident angle \(\theta_i\), same to the reflection angle, and the angle of refraction
\(\theta_t\).</p>
<p>The amount of light reflected is described by the <strong><em>Fresnel reflectance</em></strong> \(F\) function, which
depends on \(\theta_i\). In real-time rendering a typical approximation of the Fresnel
reflectance equation is the Schlick equation</p>
<p>$$F \approx F_0 + (1-F_0)(1-(n\cdot l)^+)^5,$$</p>
<p>where \(F_0 = ((n-1)/(n+1))^2\). \(F_0\) is usually interpreted as the specular color of the surface.</p>
<blockquote>
<p>The transmitted waves continue to interact with the medium and part of it gets absorbed.
The rest gets scattered back to the outside through a different surface
point. This light is called the <strong><em>subsurface-scattered</em></strong>
light will compose our diffuse component. However, let&rsquo;s keep focusing only on the
reflected light for now.</p>
</blockquote>
<h2 id="the-microgeometry-of-surfaces">The microgeometry of surfaces<a href="#the-microgeometry-of-surfaces" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<p>As you can see, the normal of the surface has a huge influence on the final directions of
light rays. When dealing with PBR, we don&rsquo;t consider any surface as perfectly aligned, so even flat
surfaces present several variations on their normal vectors. Such variations happen in a very small scale of its geometry (much smaller than a pixel actually). They are called the <strong><em>microgeometry</em></strong>
of the surface.</p>

  <img src="/img/posts/pbr/microgeometry.svg"  class="center"  />


<p>It is infeasible to represent the microgeometry in a mesh, so we rely on the
statistical distribution of their normals. The more variation we have, more light is
reflected in different directions and we get a bigger and smoother specular lobe. This variation will determine the <strong><em>roughness</em></strong> of the
surface geometry (more on that later).</p>
<p>In order to model the microgeometry, we use the <em>microfacet theory</em>. The idea is that
the microgeometry is actually composed of lots of <em>microfacets</em>, and each microfacet has a
normal \(m\) an therefore an individual BRDF \(f_\mu(l,v,m)\) attached to it. The combination of all
microfacet BRDFs give the global surface BRDF.</p>
<p>The normals of all microfacets are described by a <strong><em>normal distribution function</em></strong> (NDF) \(D(m)\)
&ndash; no relation to the same term used in probability.
Most surfaces have NDFs that show a strong peak at the surface normal \(n\). It happens that,
several microfacets can be occluded by others depending on the view direction <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>, which
impacts directly on the visible surface area, and therefore affects the amount of reflected
radiance. Thus, we need to define a <strong><em>distribution of visible normals</em></strong> \(G_1\), given
by Smith as
$$G_1(m,v) = \frac{\chi^+(m\cdot v)}{1 + \Lambda(v)},$$
where \(\chi^+\) is the characteristic function:
$$\chi^+(x) = \begin{cases}1, &amp; x &gt; 0\\ 0, &amp; x \leq 0 \end{cases},$$
and \(\Lambda\) is specific to each
type of NDF. The final BRDF equation is:
$$f(l,v) = \int_{m\in\Omega}f_\mu(l,v,m)G_2(l,v,m)D(m)\frac{(m\cdot l)^+}{|n\cdot l|}\frac{(m\cdot v)^+}{|n\cdot v|}dm,$$</p>
<p>where \(G_2\) is the <strong><em>joint masking-shadowing function</em></strong>, which incorporates shadowing of
microfacets, and is defined as</p>
<p>$$G_2(l,v,m) = G_1(v,m)G_1(l,m).$$</p>
<p>Before going any further on NDFs and the \(\Lambda\) term in \(G_1\), lets put some practical
observations here. In real-time rendering we don&rsquo;t want to solve an integral in the shader.
However, if we consider each microfacet being a Fresnel mirror &ndash; light being reflected to a single direction from \(\theta_i\) &ndash; then, for a given view direction \(v\), only microfacets with the
normal \(m\) aligned to the half vector
$$h = \frac{l + v}{\parallel l + v\parallel}$$
will contribute to the outgoing radiance. This way the integral results in the specular BRDF
$$f_{spec}(l,v) = \frac{F(h,l)G_2(l,v,h)D(h)}{4|n\cdot l||n\cdot v|}.$$</p>
<blockquote>
<p>Note that since we assumed microfacets as Fresnel mirrors, then the microfacet BRDF \(f_\mu\)
is defined as the Fresnel reflectance \(F\). Also, this is the specular
contribution we get, we will also need a diffuse contribution to get a complete model.</p>
</blockquote>
<hr>
<p><a href="http://graphicrants.blogspot.com/2013/08/specular-brdf-reference.html">Here</a> you can find
a list of NDF, \(F\) and \(G_1\) functions.</p>
<hr>
<p>The shader code for our specular contribution will be like this:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#75715e">// surface normal at fragment
</span><span style="color:#75715e"></span>vec3 n <span style="color:#f92672">=</span> normalize(fragment_normal);
<span style="color:#75715e">// view direction
</span><span style="color:#75715e"></span>vec3 v <span style="color:#f92672">=</span> normalize(camera_position <span style="color:#f92672">-</span> fragmen_position);
<span style="color:#75715e">// light direction
</span><span style="color:#75715e"></span>vec3 l <span style="color:#f92672">=</span> normalize(light_position <span style="color:#f92672">-</span> fragment_position);
<span style="color:#75715e">// half vector
</span><span style="color:#75715e"></span>vec3 h <span style="color:#f92672">=</span> normalize(v <span style="color:#f92672">+</span> l);
<span style="color:#75715e">// incoming radiance
</span><span style="color:#75715e"></span>vec3 radiance <span style="color:#f92672">=</span> light_color;
<span style="color:#75715e">// compute specular BRDF terms
</span><span style="color:#75715e"></span><span style="color:#66d9ef">float</span> NDF <span style="color:#f92672">=</span> normalDistributionFunction(n, h, roughness);
<span style="color:#66d9ef">float</span> G2   <span style="color:#f92672">=</span> geometricShadowing(n, h, v, l, roughness);
vec3 F    <span style="color:#f92672">=</span> fresnel(v, h, f0);
<span style="color:#75715e">// compute specular BRDF integral
</span><span style="color:#75715e"></span>vec3 nominator    <span style="color:#f92672">=</span> NDF <span style="color:#f92672">*</span> G2 <span style="color:#f92672">*</span> F;
<span style="color:#66d9ef">float</span> denominator <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span> <span style="color:#f92672">*</span> max(dot(N, V), <span style="color:#ae81ff">0.0</span>) <span style="color:#f92672">*</span> max(dot(N, L), <span style="color:#ae81ff">0.0</span>);
vec3 specular <span style="color:#f92672">=</span> nominator <span style="color:#f92672">/</span> max(denominator, <span style="color:#ae81ff">0.001</span>);
<span style="color:#75715e">// reflectance equation
</span><span style="color:#75715e"></span>vec3 Lo <span style="color:#f92672">=</span> ...
</code></pre></div><h2 id="the-diffuse-contribution">The Diffuse Contribution<a href="#the-diffuse-contribution" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<p>Let&rsquo;s now consider the transmitted light that get scattered back to the outside medium.
In this case, we will be interested in how much of the transmitted light is not absorbed.
This quantity is named <strong><em>subsurface albedo</em></strong> and is represented by the symbol
\(\rho_{ss}\). Usually, \(\rho_{ss}\) is interpreted as the diffuse color of the surface
and has 3 components, to match the RGB model.</p>
<p>Depending on the distances traveled by transmitted light inside the material before it leaves the
surface a different model must be used. So far we&rsquo;ve considered the microfacet theory based models
for specular reflection, which can be used in cases where light travels small distances
restricted to microfacet sizes. Such models of local subsurface scattering, based on the
roughness of the surface, are called rough-surface diffuse models.</p>
<p>Using the fact that the Fresnel reflectance \(F\) gives us the amount of light that is directly reflected,
we can use its counterpart to compute the diffuse term</p>
<p>$$f_{diff}(l,v) = (1 - F(h,l))\frac{\rho_{ss}}{\pi}.$$
The previous model uses the Lambertian model, which assumes that light is uniformly distributed under the
surface, which is not the case for several types of material. This model also does not take into account
that light gets refracted when leaving the surface as well. The Shirley model addresses these issues:</p>
<p>$$f_{diff}(l,v) = \frac{21}{20\pi}(1-F_0)\rho_{ss}(1-(1-(n\cdot l)^+)^5)(1-(1-(n\cdot v)^+)^5)$$</p>
<p>In the case where traveled distances are greater than microfacet scales, then smooth-surface diffuse
models should be used. An example is the Hammon diffuse model:</p>
<p>$$f_{diff}(l,v) = \chi^+(n\cdot l)\chi^+(n\cdot v)\frac{\rho_{ss}}{\pi}((1 - \alpha)f_{smooth} + \alpha f_{rough} + \rho_{ss}f_{multi}),$$
where
$$f_{smooth} = \frac{21}{20}(1 - F_0)(1 - (1- n\cdot l)^5)(1 - (1- n\cdot v)^5),$$
$$f_{rough} = k_{facing}(0.9 - 0.4k_{facing})(\frac{0.5 + n\cdot h}{n\cdot h}),$$
$$k_{facing} = 0.5 + 0.5 (l\cdot v),$$
$$f_{multi} = 0.3641\alpha,$$
and \(\alpha\) is the GGX specular roughness.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><strong>Solid angle</strong> is the area of a piece of surface projected onto the unitsphere. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><strong>Steradian</strong> is the measurement unit of the solid angle. As we measure angles in radians, we measure solid angles in steradians. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Here we assume that there is no participating media in the space lights travel from the surface
and the camera, so its radiance doesn&rsquo;t change. <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p><strong>Index of Refraction</strong> (IOF) represents the ration between the wave velocities,
original and new, when passing through a medium. <a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>Just like big mountains hiding smaller ones from our sight. <a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

      </div></div>

  

  

</div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2022 Powered by <a href="http://gohugo.io">Hugo</a></span>
    
        <span>:: Theme made by <a href="https://twitter.com/panr">panr</a></span>
      </div>
  </div>
</footer>

<script src="/assets/main.js"></script>
<script src="/assets/prism.js"></script>








  
</div>

</body>
</html>
